{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "248.182px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "GS_01_Argovis_TropicalCyclones_SeaIce.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ByPWoClRCup"
      },
      "source": [
        "# Investigating upper ocean variability  during tropical cyclones and seasonal  sea ice formation and melting: Argovis APIs exposed to co-locate oceanic and atmospheric datasets\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Jq67f4RCuq"
      },
      "source": [
        "## 1.1 Author(s)\n",
        "- Author1 = {\"name\": \"Giovanni Seijo-Ellis\", \"affiliation\": \"Department of Atmospheric and Oceanic Sciences, University of Colorado Boulder, Boulder, CO, United States\", \"email\": \"giovanni.seijo@colorado.edu\", \"orcid\": \"0000-0001-5626-9170\"}\n",
        "- Author2 = {\"name\": \"Donata Giglio\", \"affiliation\": \"Department of Atmospheric and Oceanic Sciences, University of Colorado Boulder, Boulder, CO, United States\", \"email\": \"donata.giglio@colorado.edu\"}\n",
        "- Author3 = {\"name\": \"Sarah Purkey\", \"affiliation\": \"CASPO, Scripps Institution of Oceanography, La Jolla, CA, United States.\", \"email\": \"spurkey@ucsd.edu\"}\n",
        "- Author4 = {\"name\": \"Megan Scanderbeg\", \"affiliation\": \"CASPO, Scripps Institution of Oceanography, La Jolla, CA, United States.\", \"email\": \"mscanderbeg@ucsd.edu\"}\n",
        "- Author5 = {\"name\": \"Tyler Tucker\", \"affiliation\": \"Department of Atmospheric and Oceanic Sciences, University of Colorado Boulder, Boulder, CO, United States\", \"email\": \"tytu6322@colorado.edu\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRmJ8CLMRCur"
      },
      "source": [
        "## 1.2 Purpose\n",
        "Argovis (at argovis.colorado.edu) is a web app and database that allows easy access to Argo profile observations of the global ocean and other earth science datasets using a browser and/or via Application Programming Interfaces (APIs). This notebook serves two main purposes: (i) introducing two new APIs available to access tropical cyclone (TC) track data and sea-ice concentration from the Southern Ocean State Estimate (SOSE), and (ii) leverage the capabilities of these APIs with interactive educational activities suitable for courses in oceanography and air-sea interactions. In addition, the notebook serves as a basis for research applications of the two APIs, e.g. to co-locate these datasets with oceanic observations (e.g. profiles of ocean temperature and salinity from Argo).\n",
        "\n",
        "## 1.3 Technical contributions\n",
        "- Introduction of new Argovis API to access TC track data.\n",
        "- Introduction of new Argovis API to access sea-ice concentration from SOSE.\n",
        "- Development of framework leveraging new and existing Argovis APIs to co-locate observations with TCs in the global ocean, and sea-ice in the Southern Ocean.\n",
        "- Development of educational and research framework to examine changes in temperature and salinity oceanic profiles before and after events of interest via defined functions.\n",
        "- The authors note that this notebook also uses four functions developed by [Tucker, Giglio, Scanderbeg (2020)](https://www.essoar.org/doi/10.1002/essoar.10504304.1), i.e.: get_profile, get_platform_profiles, parse_into_df, parse_into_df_plev (with minor modifications)\n",
        "- In addition,  the function get_hurricane_marker leverages information from https://www.unidata.ucar.edu/blogs/developer/entry/metpy-mondays-150-hurricane-markers\n",
        "\n",
        "\n",
        "## 1.4 Methodology\n",
        "This notebook guides the user on an exploration of changes in oceanic properties before and after two distinct events: (i) passage of a tropical cyclone and, (ii) formation of sea-ice. To do so, we have defined a series of functions that leverage new and existing Argovis APIs. Additionally, the user will be given the opportunity to explore different events via user-defined parameters. The user will be guided through a series of questions in each activity with the goal of enhancing the educational outcomes of this notebook. \n",
        "\n",
        "In the following there will be two activities. The first activity (Section 4) will guide the user to co-locate and plot Argo float profiles of temperature and salinity along the track of a tropical cyclone before and after its passage. The second activity (Section 5) will guide the user to co-locate and plot Argo float profiles of temperature and salinity in the Southern Ocean before and after the float is believed to be trapped under sea-ice.\n",
        "\n",
        "\n",
        "## 1.5 Results\n",
        "Upon completion of the activities on this notebook, the student will have gained new scientific knowledge on ocean properties changes due to: a) passages of tropical cyclones, and b) formation/melting of sea-ice. Here we present a general overview of the results of each activity and point the student toward useful references on each topic. The student is expected to provide their own results at the end of each activity. The student’s results will be based on their own plots, answers to questions, and references provided throughout the notebook.\n",
        "\n",
        "After completing the first activity (Section 4), an examination of temperature and salinity profiles before and after the passage of the selected tropical cyclone will show two general results. First, that temperature decreases after the passage of the tropical cyclone (that is, the ocean cools down). Second, that salinity changes after the passage of the tropical cyclone. The strong winds associated with a TC induce air-sea exchanges of heat and mixing in the upper ocean. As a result, cold waters from the subsurface rise and replace the warmer waters at the ocean surface leaving  a cold wake behind the tropical cyclone. Mixing induced changes in salinity depend on the initial structure of the salinity profile. In regions where salinity increases with depth, TC-induced mixing will result in a saltier upper ocean. For more information and details on air-sea exchanges during a TC see: [Steffen et al. (2018)](https://journals.ametsoc.org/view/journals/phoc/48/9/jpo-d-17-0262.1.xml) and [Trenberth et al. (2018)](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018EF000825).\n",
        "\n",
        "For the second activity (Section 5), the student will examine changes in ocean temperatures and salinity during formation/melting of sea-ice in the Southern Ocean. The student will find that when sea-ice forms, the water underneath becomes colder and more saline (vice versa when sea-ice melts). When sea-ice forms, radiation from the sun is blocked by sea-ice and does not reach the water below it. Most of the radiation is reflected and thus does not warm the ocean resulting in cooling of the sea water. In addition, during the formation of sea-ice, a process called brine-rejection occurs. Because salt is rejected as ice forms, the water surrounding the newly formed ice becomes saltier (thus, denser). The process is an important driver of the thermohaline circulation. For more information and details see: #is there a good review style paper that discusses this and could be included here?\n",
        "\n",
        "## 1.7 Funding\n",
        "Include references to awards that supported this research. Add as many award references as you need.\n",
        "\n",
        "- Award1 = {\"agency\": \"US National Science Foundation\", \"award_code\": \"2026776\", \"award_URL\": \"https://nsf.gov/awardsearch/showAward?AWD_ID=1928305&HistoricalAwards=false\"}\n",
        "- Award2 = {\"agency\": \"agency\", \"award_code\": \"1928305\", \"award_URL\": \"https://www.nsf.gov/awardsearch/showAward?AWD_ID=2026776&HistoricalAwards=false\"}\n",
        "\n",
        "\n",
        "## 1.8 Keywords\n",
        "Include up to 5 keywords, using the template below.\n",
        "\n",
        "keywords= [“argovis”,“argo floats”,”tropical cyclones”,”sea-ice”, “oceanic profiles”]\n",
        "\n",
        "## 1.8 Citation\n",
        "Seijo-Ellis,G., Giglio, D., Purkey, S., Scanderbeg, M., Tucker, T. (2021). Investigating  upper ocean variability  during tropical cyclones and seasonal  sea ice formation and melting: Argovis APIs exposed to co-locate oceanic and atmospheric datasets.[url to github]. A DOI will be assigned to the notebook after review.\n",
        "\n",
        "## 1.9 Suggested next steps\n",
        "This notebook can be modified to improve the current methodology for more rigorous analysis and/or further exploration. The following suggestions can be incorporated into the notebook:\n",
        "- Improve profile selection function to include a distance from TC track parameter instead of a predefined box around each point of the tropical cyclone track. The function should verify that the before and after profiles are within a user-defined distance from one another.\n",
        "- The code can be extended to include biogeochemical variables when available and analyze how these change during events of interest.\n",
        "\n",
        "\n",
        "\n",
        "## 1.10 Acknowledgements \n",
        "\n",
        "The authors would like to thank the EarthCube Office for guidance provided during the preparation of this notebook. The authors would also like to thank the anonymous reviewers for the feedback. \n",
        "\n",
        "This notebook template extends the original notebook template provided with the jupytemplate extension [5]. It is a result of collaboration between the TAC Working Group and the EarthCube Office. The template is licensed under a [Creative Commons Attribution 4.0 International License.](http://creativecommons.org/licenses/by/4.0/)\n",
        "\n",
        "This notebook uses ocean profile data collected and made publically available through the international [Argo program](http://www.argo.net/) and sea ice data provided from [SOSE](http://sose.ucsd.edu/sose.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yZSFpFsRCus"
      },
      "source": [
        "# 2. Setup\n",
        "---\n",
        "\n",
        "## 2.1 Library import\n",
        "Import all the required Python libraries.\n",
        "\n",
        "The code cell below is an example.\n",
        "When submitting your notebook, make sure that all external libraries are included in the requirements or environment file and library versions are explictly defined.\n",
        "\n",
        "It is a good practice to organize the imported libraries by functionality, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "JBfKSOM2RCus",
        "outputId": "350449d4-be83-451b-d08c-c47b20824e27"
      },
      "source": [
        "# Data manipulation\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import interpolate\n",
        "from itertools import compress\n",
        "from datetime import datetime\n",
        "from datetime import timedelta  \n",
        "\n",
        "# Visualizations\n",
        "import matplotlib\n",
        "import matplotlib.pylab as plt\n",
        "from matplotlib import cm\n",
        "import matplotlib.dates as mdates\n",
        "import cartopy.crs as ccrs\n",
        "#import cartopy.feature as cft\n",
        "\n",
        "from svgpath2mpl import parse_path\n",
        "%matplotlib inline\n",
        "\n",
        "# Autoreload extension\n",
        "if 'autoreload' not in get_ipython().extension_manager.loaded:\n",
        "    %load_ext autoreload   \n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-df8c32924d5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mccrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#import cartopy.feature as cft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cartopy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo install cartopy, click the button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jfz-DEt7RCuu"
      },
      "source": [
        "\n",
        "# 3. Functions Definitions\n",
        "---\n",
        "In this section all functions leveraged throughout the notebook are defined. Various of these function leverage Argovis APIs to query data based on user-defined parameters. Thus, data imports occur in sections 4.2 and 5.2 as part of the interactive activities. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeMQIdhAD3K1"
      },
      "source": [
        "## 3.1 Functions for tropical cylone activities (Section 4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7gPIGybzc5y"
      },
      "source": [
        "# get a tropical cyclone by date and year\n",
        "def get_TCs_byNameYear(tc_name,tc_year):\n",
        "    url = 'https://argovis.colorado.edu/tc/findByNameYear?name='+tc_name+'&year='+str(tc_year) #2018-07-15\n",
        "    print(url)\n",
        "    resp = requests.get(url)\n",
        "    # Consider any status other than 2xx an error\n",
        "    if not resp.status_code // 100 == 2:\n",
        "        return \"Error: Unexpected response {}\".format(resp)\n",
        "    data = resp.json()\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBy_KLXazi1e"
      },
      "source": [
        "# get tropical cyclones (or SH storms) by date\n",
        "def get_TCs_byDate(startDate,endDate):\n",
        "    url = 'https://argovis.colorado.edu/tc/findByDateRange?startDate='+startDate+'T00:00:00&endDate='+endDate+'T00:00:00' #2018-07-15\n",
        "    print(url)\n",
        "    resp = requests.get(url)\n",
        "    # Consider any status other than 2xx an error\n",
        "    if not resp.status_code // 100 == 2:\n",
        "        return \"Error: Unexpected response {}\".format(resp)\n",
        "    data = resp.json()\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrs-zo0-zlc_"
      },
      "source": [
        "# create a marker for tropical cyclones\n",
        "def get_hurricane_marker():\n",
        "    hurricane = parse_path(\"\"\"M 188.79857,492.55018 L 180.09663,484.17671 L 188.57725,474.97463 \n",
        "     C 212.44187,449.07984 230.37031,423.34927 246.04359,392.5 \n",
        "     C 254.14781,376.5487 265.0005,350.78866 265.0005,347.50373 \n",
        "     C 265.0005,346.53236 263.21255,347.40666 259.7505,350.07094 \n",
        "     C 251.67361,356.28665 233.85001,364.64767 222.5005,367.54485 \n",
        "     C 204.24051,372.20605 178.92084,371.97166 159.45635,366.96123 \n",
        "     C 147.77122,363.95331 130.93184,355.3283 122.0005,347.77659 \n",
        "     C 95.11018,325.04006 81.65749,291.36529 81.74139,247 \n",
        "     C 81.78993,221.33674 85.91479,197.1747 94.55247,171.95714 \n",
        "     C 111.06665,123.74428 136.98179,82.210848 180.29075,34.54693 \n",
        "     L 185.6999,28.59386 L 189.6002,31.718323 \n",
        "     C 191.74536,33.436777 195.9159,37.308373 198.86805,40.32187 \n",
        "     L 204.23561,45.800955 L 193.66355,57.483549 \n",
        "     C 168.69038,85.080007 151.53704,109.91644 136.8182,139.79028 \n",
        "     C 130.67851,152.2516 118.91503,180.17836 119.52809,180.83739 \n",
        "     C 119.70071,181.02295 122.91512,178.62979 126.67122,175.51926 \n",
        "     C 144.84799,160.46658 171.06913,152.9127 200.0005,154.39429 \n",
        "     C 227.96505,155.82638 249.78837,164.40176 267.15103,180.78081 \n",
        "     C 291.49094,203.74185 302.41509,234.21538 302.36063,279 \n",
        "     C 302.33536,299.77768 300.97355,312.12979 296.41891,332.89349 \n",
        "     C 286.70405,377.18157 262.85893,424.36347 228.55502,467.17452 \n",
        "     C 219.26505,478.76833 199.25099,501.02345 198.17004,500.96183 \n",
        "     C 197.80179,500.94084 193.58463,497.15559 188.79857,492.55018 \n",
        "     z M 212.92994,343.99452 C 242.28307,336.85605 266.31414,312.68729 \n",
        "     273.9846,282.59004 C 276.76052,271.6979 276.75301,253.72727 273.96762,242 \n",
        "     C 266.78666,211.76606 241.98871,187.12253 211.5005,179.92186 \n",
        "     C 203.8953,178.12567 200.40831,177.86988 189.0005,178.27134 \n",
        "     C 173.93019,178.80168 167.30498,180.26871 156.08925,185.55888 \n",
        "     C 132.8924,196.50023 116.23621,216.81521 109.90648,241.88639 \n",
        "     C 108.09535,249.06004 107.84969,252.38603 108.2077,264.88639 \n",
        "     C 108.58615,278.10034 108.93262,280.39476 111.82513,288.842 \n",
        "     C 113.58452,293.98009 116.23139,300.28009 117.70707,302.842 \n",
        "     C 137.50495,337.21285 174.70639,353.29022 212.92994,343.99452 z\"\"\")\n",
        "    return hurricane\n",
        "hurricane = get_hurricane_marker()\n",
        "hurricane.vertices -= hurricane.vertices.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CsP1JwDzog_"
      },
      "source": [
        "# this function is from Tucker, Giglio, Scanderbeg 2020 (https://www.essoar.org/doi/10.1002/essoar.10504304.1)\n",
        "# get profiles in any shape of interest\n",
        "def get_selection_profiles(startDate, endDate, shape, presRange=None, printUrl=True):\n",
        "    url = 'https://argovis.colorado.edu/selection/profiles'\n",
        "    url += '?startDate={}'.format(startDate)\n",
        "    url += '&endDate={}'.format(endDate)\n",
        "    url += '&shape={}'.format(shape)\n",
        "    if presRange:\n",
        "        pressRangeQuery = '&presRange=' + presRange\n",
        "        url += pressRangeQuery\n",
        "    if printUrl:\n",
        "        print(url)\n",
        "    resp = requests.get(url)\n",
        "    # Consider any status other than 2xx an error\n",
        "    if not resp.status_code // 100 == 2:\n",
        "        return \"Error: Unexpected response {}\".format(resp)\n",
        "    selectionProfiles = resp.json()    \n",
        "    return selectionProfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZECiy_6Xzqy5"
      },
      "source": [
        "# this function is from Tucker, Giglio, Scanderbeg 2020 (https://www.essoar.org/doi/10.1002/essoar.10504304.1)\n",
        "def get_platform_profiles(platform_number):\n",
        "    url = 'https://argovis.colorado.edu/catalog/platforms/{}'.format(platform_number)\n",
        "    resp = requests.get(url)\n",
        "    # Consider any status other than 2xx an error\n",
        "    if not resp.status_code // 100 == 2:\n",
        "        return \"Error: Unexpected response {}\".format(resp)\n",
        "    platformProfiles = resp.json()\n",
        "    return platformProfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue8JzL0tzv6A"
      },
      "source": [
        "# this function is from Tucker, Giglio, Scanderbeg 2020 (https://www.essoar.org/doi/10.1002/essoar.10504304.1)\n",
        "# parse profiles into a dataframe\n",
        "def parse_into_df(profiles):\n",
        "    meas_keys = profiles[0]['measurements'][0].keys()\n",
        "    df = pd.DataFrame(columns=meas_keys)\n",
        "    for profile in profiles:\n",
        "        profileDf = pd.DataFrame(profile['measurements'])\n",
        "        profileDf['cycle_number'] = profile['cycle_number']\n",
        "        profileDf['profile_id'] = profile['_id']\n",
        "        profileDf['lat'] = profile['lat']\n",
        "        profileDf['lon'] = profile['lon']\n",
        "        profileDf['date'] = profile['date']\n",
        "        profileDf['position_qc'] = profile['position_qc']\n",
        "        df = pd.concat([df, profileDf], sort=False)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbhWN_BCz3IK"
      },
      "source": [
        "def plot_tracks_time_in_col(TCs_Dict,df_ctag='wind',df_title=''):\n",
        "    for i in range(0,len(TCs_Dict)):\n",
        "        df  = pd.DataFrame(TCs_Dict[i]['traj_data'])\n",
        "        #dti = pd.to_datetime(df['timestamp'])\n",
        "        #plt.plot(df['lon'],df['lat'],transform=ccrs.Geodetic(),c='k')\n",
        "        plt.scatter(df['lon'],df['lat'],transform=ccrs.Geodetic(),s=5,c=df[df_ctag])#c=mdates.date2num(dti))\n",
        "    cb = plt.colorbar()\n",
        "    tt = plt.title()\n",
        "    # loc = mdates.AutoDateLocator()\n",
        "    # cb.ax.yaxis.set_major_locator(loc)\n",
        "    # cb.ax.yaxis.set_major_formatter(mdates.ConciseDateFormatter(loc))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isaHaATXz6on"
      },
      "source": [
        "def TC_and_storms_view(startDate,endDate,tag_TC_or_SH_FILT='TC'):\n",
        "    TCs_Dict = get_TCs_byDate(startDate,endDate=endDate)\n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "\n",
        "    ax = plt.axes(projection=ccrs.Mollweide())\n",
        "    ax.stock_img()\n",
        "\n",
        "    bool_list = [] #True*len(TCs_Dict)\n",
        "    for x in TCs_Dict:\n",
        "        if ('SH_FILT' in tag_TC_or_SH_FILT):\n",
        "            df_title = ' Southern Hemisphere storms intensity '\n",
        "            df_ctag = 'intensity'\n",
        "            bool_list.append('SH_FILT' in x['_id'])\n",
        "        else:\n",
        "            df_title = 'Tropical Cyclone tracks and winds (color,units)'\n",
        "            df_ctag = 'wind'\n",
        "            bool_list.append(~('SH_FILT' in x['_id']))\n",
        "            \n",
        "    output_select = list(compress(TCs_Dict, bool_list))\n",
        "    \n",
        "    plot_tracks_time_in_col(list(compress(TCs_Dict, bool_list)),df_ctag,df_title)\n",
        "    return output_select"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0wM6nWqz-yC"
      },
      "source": [
        "def plot_prof(dataX,dataY,xlab,ylab,xlim,ylim,col):\n",
        "\n",
        "    plt.plot(dataX,dataY,color=col,linewidth=5)\n",
        "\n",
        "#     #ax.set_title('An Argo Profile \\n in the style of XKCD')\n",
        "    plt.gca().set_xlabel(xlab,fontsize=24)\n",
        "    plt.gca().set_ylabel(ylab,fontsize=24)\n",
        "    plt.ylim(ylim)\n",
        "    if xlim:\n",
        "        plt.xlim(xlim)\n",
        "    plt.gca().invert_yaxis()\n",
        "    #ax.invert_yaxis()\n",
        "    \n",
        "    for tick in plt.gca().xaxis.get_majorticklabels():  # example for xaxis\n",
        "        tick.set_fontsize(24) \n",
        "    for tick in plt.gca().yaxis.get_majorticklabels():  # example for xaxis\n",
        "        tick.set_fontsize(24) \n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hevWdpdQECV1"
      },
      "source": [
        "## 3.2 Functions for sea-ice activities (Section 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAeZQmxbEG4g"
      },
      "source": [
        "def get_SOSE_sea_ice(xreg,yreg,date,printUrl=True):\n",
        "    # yreg, xreg, date should be lists\n",
        "    url  = 'https://argovis.colorado.edu/griddedProducts/nonUniformGrid/window?'\n",
        "    url += 'gridName=sose_si_area_1_day_sparse&presLevel=0&'\n",
        "    url += 'latRange={}'.format(yreg)\n",
        "    url += '&lonRange={}'.format(xreg)\n",
        "    url += '&date={}'.format(date)\n",
        "    if printUrl:\n",
        "        print(url)\n",
        "    resp = requests.get(url)\n",
        "    # Consider any status other than 2xx an error\n",
        "    if not resp.status_code // 100 == 2:\n",
        "        return \"Error: Unexpected response {}\".format(resp)\n",
        "    selectionSeaIce = resp.json()    \n",
        "    return selectionSeaIce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf_xLZrIEN8g"
      },
      "source": [
        "def parse_into_df_SeaIce(selectionSeaIce):\n",
        "    meas_keys = selectionSeaIce[0]['data'][0].keys()\n",
        "    df = pd.DataFrame(columns=meas_keys)\n",
        "    for data in selectionSeaIce[0]['data']:\n",
        "        bfrDf = pd.DataFrame(data={'lon':  [data['lon']], 'lat':  [data['lat']], 'value':  [data['value']]}) #pd.DataFrame(data={'lon':  data['lon'], 'lat':  data['lat']})\n",
        "        df = pd.concat([df, bfrDf], sort=False)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlbdXUkGESmp"
      },
      "source": [
        "# this function is from Tucker, Giglio, Scanderbeg 2020 (https://www.essoar.org/doi/10.1002/essoar.10504304.1)\n",
        "def parse_into_df_plev(profiles, plev):\n",
        "    plevProfileList = []\n",
        "    for profile in profiles:\n",
        "        profileDf_bfr = pd.DataFrame(profile['measurements'])\n",
        "        plevProfile = profile\n",
        "        fT = interpolate.interp1d(profileDf_bfr['pres'], profileDf_bfr['temp'], bounds_error=False)\n",
        "        plevProfile['temp'] = fT(plev)\n",
        "        # some of the profiles in Argovis may not have salinity \n",
        "        # (either because there is no salinity value in the original Argo file or the quality is bad)\n",
        "        try:\n",
        "            fS = interpolate.interp1d(profileDf_bfr['pres'], profileDf_bfr['psal'], bounds_error=False)\n",
        "            plevProfile['psal'] = fS(plev)\n",
        "        except:\n",
        "            plevProfile['psal'] = np.nan #  No salinity found in profile\n",
        "        plevProfile['pres'] = plev\n",
        "        plevProfileList.append(plevProfile)\n",
        "    df = pd.DataFrame(plevProfileList)\n",
        "    df = df.sort_values(by=['cycle_number'])\n",
        "    df = df.reset_index(drop=True)\n",
        "    # print all that is available (only some of the info will be stored in the output dataframe, yet users can add more if interested)\n",
        "    print(df.keys())\n",
        "    df = df[['cycle_number','_id','date','lon','lat','pres','temp','psal','position_qc','date_qc']]\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfPLSMQSEUar"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRXjjKXORCuu"
      },
      "source": [
        "# 4. Changes in oceanic properties before and after the passage of a tropical cyclone\n",
        "---\n",
        "In this first part of the analysis, the user will extract and plot all Tropical Cyclones and Southern Hemisphere extra tropical storms for a particular time-window (defined by the user) via the new TC/storm track data Argovis API. The user will then obtain the names of the plotted TCs (when available) and will be able to choose any TC of interest. Once a TC of interest has been identified, a second API will be used to co-locate Argo observations along the track of interest using a user-defined co-location strategy. A map with the TC track and Argo float locations of interest will be generated. We then compare the dates of the observations with the dates of the TC’s passage to identify profiles before and after. The notebook will print available observations along the track before and after the TC’s passage. Finally, a plot of temperature and salinity profiles is generated. The profiles are color coded: black (before TC passage), red (after TC passage).\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EniJ5jkb1TV7"
      },
      "source": [
        "## 4.1 Parameter definitions\n",
        "---\n",
        "Here the user will define the first set of parameters to begin the first activity. However, the user will define additional parameters as they advance through the notebook.\n",
        "\n",
        "Select the time window of interest:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Cpv6ug1SU-"
      },
      "source": [
        "start = '2017-12-20'\n",
        "end   = '2018-02-15'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pN68P-a1WSc"
      },
      "source": [
        "## 4.2 Data Processing and Analysis\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oB-wqC-2urp"
      },
      "source": [
        "### 4.2.1 Map southern hemisphere extra-tropical storms for the window of interest:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77tXJfj31XzG"
      },
      "source": [
        "SH_storms = TC_and_stroms_view(startDate=start,endDate=end,tag_TC_or_SH_FILT='SH_FILT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Co4azln20GS"
      },
      "source": [
        "### 4.2.2 Map tropical cyclones for the window of interest:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGRCqPKI2BS0"
      },
      "source": [
        "TCs = TC_and_stroms_view(startDate=start,endDate=end) #startDate='2018-07-15',endDate='2018-09-15')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsAoEIKi3D2W"
      },
      "source": [
        "### 4.2.3 Print a list of tropical cyclones with names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX4s0GgU2oFj"
      },
      "source": [
        "for x in TCs:\n",
        "    # print(x['_id'])\n",
        "    if 'name' in x.keys():\n",
        "        print('ID: ' + x['_id']+'; '+x['name']+' '+str(x['year']))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v5jNMq-4Ldi"
      },
      "source": [
        "### 4.2.4 Select a storm from the list above (name and year):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4EuCyu34bp0"
      },
      "source": [
        "tc_name = 'maria'\n",
        "tc_year = 2017"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChoyUexs4cYI"
      },
      "source": [
        "### 4.2.5 Load the track for the storm of interest:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTLmjvX14qkZ"
      },
      "source": [
        "tc_star = get_TCs_byNameYear(tc_name,tc_year)#'humberto',2019)\n",
        "df  = pd.DataFrame(tc_star[0]['traj_data'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHB-qreh4s-w"
      },
      "source": [
        "### 4.2.6 Set parameters for the co-location of Argo float profiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1I62v2t5qPh"
      },
      "source": [
        "delta_days = 7\n",
        "dx = .75\n",
        "dy = .75\n",
        "presRange=[0,100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEpkWyxK53vQ"
      },
      "source": [
        "### 4.2.7 Map the selected tropical cyclone track and location of Argo float profiles along the track."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCb-LlZZ6QoQ"
      },
      "source": [
        "prof_beforeTC = []\n",
        "prof_afterTC  = []\n",
        "\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "\n",
        "ax = plt.axes(projection=ccrs.PlateCarree()) #Mollweide\n",
        "ax.coastlines()\n",
        "# ax.add_feature(cft.LAND)\n",
        "# ax.add_feature(cft.OCEAN)\n",
        "# ax.add_feature(cft.COASTLINE)\n",
        "# ax.add_feature(cft.BORDERS, linestyle=':')\n",
        "#ax.set_extent([xmin,xmax, ymin, ymax],crs=ccrs.PlateCarree())\n",
        "\n",
        "im = plt.scatter(df['lon'],df['lat'],transform=ccrs.Geodetic(),s=2000,marker=hurricane, \n",
        "            c=df['wind'], facecolors='none', linewidth=3.5)\n",
        "\n",
        "# look for \"before\" profiles\n",
        "dti = pd.to_datetime(df['timestamp'])\n",
        "for i in np.arange(0,len(df['lon']),1):\n",
        "    for ii in np.arange(0,2,1):\n",
        "        if ii == 0:\n",
        "            startDate=str(dti[i]-timedelta(days=delta_days))[0:10]\n",
        "            endDate=str(dti[i])[0:10]\n",
        "            mrkr = '*'\n",
        "            col = 'k'\n",
        "        else:\n",
        "            startDate=str(dti[i])[0:10]\n",
        "            endDate=str(dti[i]+timedelta(days=delta_days))[0:10]\n",
        "            mrkr = '*' \n",
        "            col = 'red'\n",
        "        shape = [[[df['lon'][i]-(dx/2),df['lat'][i]-(dy/2)],[df['lon'][i]-(dx/2),df['lat'][i]+(dy/2)],[df['lon'][i]+(dx/2),df['lat'][i]+(dy/2)],[df['lon'][i]+(dx/2),df['lat'][i]-(dx/2)],[df['lon'][i]-(dx/2),df['lat'][i]-(dy/2)]]]\n",
        "        \n",
        "        strShape = str(shape).replace(' ', '')\n",
        "        selectionProfiles = get_selection_profiles(startDate, endDate, strShape, str(presRange), printUrl=False)\n",
        "        selectionProfiles_raw = selectionProfiles\n",
        "        if len(selectionProfiles) > 0 and not isinstance(selectionProfiles,str):\n",
        "            selectionDf = parse_into_df(selectionProfiles)\n",
        "            selectionDf.replace(-999, np.nan, inplace=True)\n",
        "\n",
        "            gb     = selectionDf.groupby(by='profile_id')\n",
        "            groups = dict(list(gb))\n",
        "            gb_list = gb.groups.keys()\n",
        "            \n",
        "            if ii == 0:\n",
        "                prof_beforeTC.append(groups)\n",
        "            else:\n",
        "                prof_afterTC.append(groups)\n",
        "            for tag_id in gb_list:\n",
        "#                 print('----------------------------')\n",
        "#                 print(col)\n",
        "#                 print(tag_id)\n",
        "#                 print(groups[tag_id]['date'][0])\n",
        "#                 print('tc (time, lon, lat):')\n",
        "#                 print(dti[i])\n",
        "#                 print(df['lon'][i])\n",
        "#                 print(df['lat'][i])\n",
        "               \n",
        "                plt.plot(groups[tag_id]['lon'][0],groups[tag_id]['lat'][0],mrkr,transform=ccrs.Geodetic(),markersize=15,linewidth=4,color=col)\n",
        "                \n",
        "#                 if groups[list(gb_list)[j]]['lon'][0]>=xmin and groups[list(gb_list)[j]]['lon'][0]<=xmax and \\\n",
        "#                 groups[list(gb_list)[j]]['lat'][0]>=ymin and groups[list(gb_list)[j]]['lat'][0]<=ymax:\n",
        "                if col=='k':\n",
        "                    ax.text(groups[tag_id]['lon'][0]+.25, groups[tag_id]['lat'][0], tag_id,transform=ccrs.Geodetic(),color=col)\n",
        "                elif col=='red':\n",
        "                    ax.text(groups[tag_id]['lon'][0]+.25, groups[tag_id]['lat'][0], tag_id,transform=ccrs.Geodetic(),color=col)\n",
        "        else:\n",
        "            if ii == 0:\n",
        "                prof_beforeTC.append([])\n",
        "            else:\n",
        "                prof_afterTC.append([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvOvdo-B6UeV"
      },
      "source": [
        "### 4.2.8 Print a list of Argo float profiles before and after the passage of the tropical. Plot the profiles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsPdGLH76pkL"
      },
      "source": [
        "for x,y in zip(prof_beforeTC,prof_afterTC):\n",
        "    if any(x) and any(y):\n",
        "        print('-------------')\n",
        "        # temperature\n",
        "        fig = plt.figure(figsize=(20,10))\n",
        "        plt.subplot(121)\n",
        "        for d in x.keys():\n",
        "            print('Temperature, before (black): ' + d)\n",
        "            plot_prof(dataX=x[d]['temp'],dataY=x[d]['pres'],xlab='Temperature, degC',ylab='Pressure, dbar',xlim=[],ylim=presRange,col='k')\n",
        "        for d in y.keys():\n",
        "            print('Temperature, after (red): ' + d)\n",
        "            plot_prof(dataX=y[d]['temp'],dataY=y[d]['pres'],xlab='Temperature, degC',ylab='Pressure, dbar',xlim=[],ylim=presRange,col='r')\n",
        "        # salinity\n",
        "        plt.subplot(122)\n",
        "        for d in x.keys():\n",
        "            print('Salinity, before (black): ' + d)\n",
        "            try:\n",
        "                plot_prof(dataX=x[d]['psal'],dataY=x[d]['pres'],xlab='Salinity, psu',ylab='Pressure, dbar',xlim=[],ylim=presRange,col='k')\n",
        "            except:\n",
        "                pass\n",
        "        for d in y.keys():\n",
        "            print('Salinity, after (red): ' + d)\n",
        "            try:\n",
        "                plot_prof(dataX=y[d]['psal'],dataY=y[d]['pres'],xlab='Salinity, psu',ylab='Pressure, dbar',xlim=[],ylim=presRange,col='r')\n",
        "            except:\n",
        "                pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_x7t3ApRiuH"
      },
      "source": [
        "## 4.3 Activity Results\n",
        "---\n",
        "Present your results. You should leverage the information and references provided through the notebook (Sections 1.5 and 4). Make direct reference to the figures you generated throughout the activity. Use your answers to the different questions throughout the activity to guide your results narrative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNRe0sNMRlCI"
      },
      "source": [
        "insert your results here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSaOkfejeDBB"
      },
      "source": [
        "# 5. Changes in oceanic properties as sea ice forms\n",
        "---\n",
        "The second activity in this notebook will guide users to explore sea-ice coverage estimates from SOSE and examine how ocean properties (as observed by Argo floats) change as sea-ice forms. For this, we will leverage the Argo float QC flag for position : QC flag #8 or 9 for position, indicates Argo profiles measured while the float is thought to be trapped under ice (hence while the float does not surface as part of its cycle). The user will be able to select any particular date to examine. A map showing SOSE sea-ice estimate and location of Argo floats will be generated. A list of floats (thought to be) trapped under ice will be printed on screen. The user will then generate a plot of the location and QC flag for a float of interest (e.g. from the list) in order to identify when the float was thought to be under sea-ice. Finally, will generate a multi-panel plot showing: a) time series of the float’s QC flag value and fraction of sea-ice from SOSE, b) ocean temperature profiles in time as recorded by the float, and c) ocean salinity profiles in time as recorded by the float."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMAR_Pm8A93h"
      },
      "source": [
        "## 5.1 Parameter definitions\n",
        "---\n",
        "Here the user will define the first set of parameters to begin the second activity. However, the user will define additional parameters as they advance through the notebook.\n",
        "\n",
        "Define a list and date for SOSE sea-ice data extraction function (get_SOSE_sea_ice, Section 3.2):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N77od8vHFBHr"
      },
      "source": [
        "# we define lists for the input to the function that gets SOSE sea icea data\n",
        "yreg_ALL = np.arange(-90.,-10.,40.).tolist()\n",
        "xreg_ALL = np.arange(-60.,-15.,5.).tolist() #(-180.,180.,5.)\n",
        "date_ALL = ['2013-06-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtzfO-HXFKXL"
      },
      "source": [
        "## 5.2 Data Processing and Analysis\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTGiLqAqFUku"
      },
      "source": [
        "### 5.2.1 Map SOSE sea-ice estimate and location of Argo float profiles available for the region of interest. Print a list of Argo float profile IDs for those profiles believed to be under ice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39TLBkeuFx2C"
      },
      "source": [
        "shape = [[[max(xreg_ALL),min(yreg_ALL)],[max(xreg_ALL),max(yreg_ALL)],[min(xreg_ALL),max(yreg_ALL)],[min(xreg_ALL),min(yreg_ALL)],[max(xreg_ALL),min(yreg_ALL)]]]\n",
        "strShape = str(shape).replace(' ', '')\n",
        "presRange='[0,50]'\n",
        "selectionProfiles = get_selection_profiles(startDate, endDate, strShape, presRange,printUrl=False)\n",
        "selectionProfiles_raw = selectionProfiles\n",
        "if len(selectionProfiles) > 0:\n",
        "    selectionDf = parse_into_df(selectionProfiles)\n",
        "selectionDf.replace(-999, np.nan, inplace=True)\n",
        "\n",
        "color_map = plt.cm.get_cmap('Blues')\n",
        "reversed_color_map = color_map.reversed()\n",
        "\n",
        "presRange='[0,50]' # pressure range of interest for Argo profiles\n",
        "plev_presRange = 30 # a number in the middle of the pressure range of interest should work for this\n",
        "delta_argo = 3 # how many days before and after the sea ice field we query profiles for\n",
        "\n",
        "for l in np.arange(0,len(date_ALL)):\n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "    ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
        "    ax.coastlines()\n",
        "    #     ax.add_feature(cft.LAND)\n",
        "    #     ax.add_feature(cft.OCEAN)\n",
        "    #ax.stock_img()\n",
        "    ax.set_extent([-180, 180, -90, -35], crs=ccrs.PlateCarree())\n",
        "\n",
        "    # dates for argo profiles\n",
        "    bfr_startDate = datetime.strptime(date_ALL[0], '%Y-%m-%d')\n",
        "    bfr_startDate -= timedelta(days=delta_argo)\n",
        "    bfr_endDate = datetime.strptime(date_ALL[0], '%Y-%m-%d')\n",
        "    bfr_endDate += timedelta(days=delta_argo)\n",
        "\n",
        "    str_flag = True\n",
        "    for i in np.arange(0,len(xreg_ALL)-1):\n",
        "        for j in np.arange(0,len(yreg_ALL)-1):\n",
        "            try:\n",
        "                selectionSeaIce  = get_SOSE_sea_ice(xreg=xreg_ALL[i:i+2],yreg=yreg_ALL[j:j+2],date=date_ALL[l],printUrl=False)\n",
        "                df_SeaIce       = parse_into_df_SeaIce(selectionSeaIce)\n",
        "                plt.scatter(df_SeaIce['lon'],df_SeaIce['lat'],transform=ccrs.Geodetic(),s=5,cmap=reversed_color_map,c=df_SeaIce['value'])\n",
        "            except:\n",
        "                pass\n",
        "            # add Argo profiles to the plot and print float number\n",
        "            # region\n",
        "            shape = [[[max(xreg_ALL[i:i+2]),min(yreg_ALL[j:j+2])],[max(xreg_ALL[i:i+2]),max(yreg_ALL[j:j+2])],\n",
        "                      [min(xreg_ALL[i:i+2]),max(yreg_ALL[j:j+2])],[min(xreg_ALL[i:i+2]),min(yreg_ALL[j:j+2])],\n",
        "                      [max(xreg_ALL[i:i+2]),min(yreg_ALL[j:j+2])]]]\n",
        "            strShape = str(shape).replace(' ', '')\n",
        "\n",
        "            bfr_selectionProfiles     = get_selection_profiles(bfr_startDate, bfr_endDate, strShape, presRange,printUrl=False)\n",
        "\n",
        "            if len(bfr_selectionProfiles) > 0:\n",
        "                bfr_selectionDf = parse_into_df(bfr_selectionProfiles)\n",
        "                bfr_selectionDf = bfr_selectionDf.drop_duplicates('profile_id')\n",
        "                plt.plot(bfr_selectionDf['lon'],bfr_selectionDf['lat'],'+r',transform=ccrs.Geodetic())\n",
        "                \n",
        "#                 print('+++')\n",
        "#                 print(strShape)\n",
        "#                 print(bfr_selectionDf['profile_id'])\n",
        "#                 print(bfr_selectionDf['position_qc'])\n",
        "#                 print(bfr_selectionDf['lon'])\n",
        "#                 print(bfr_selectionDf['lat'])\n",
        "#                 print('+++')\n",
        "                \n",
        "                bfr2 = bfr_selectionDf.loc[bfr_selectionDf['position_qc'] == 8]\n",
        "                if len(bfr2) > 0:\n",
        "                    plt.plot(bfr2['lon'],bfr2['lat'],'or',transform=ccrs.Geodetic())\n",
        "                    if str_flag:\n",
        "                        print('>>>> Profile ID for profiles under ice (i.e. platformNumber_profileNumber) <<<<')\n",
        "                        str_flag = False\n",
        "                    print(bfr2['profile_id'])\n",
        "                    \n",
        "    colorbar = plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fqhjttTF7xN"
      },
      "source": [
        "5.2.2 Select a float of interest from the list above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVFBHQ33GVKc"
      },
      "source": [
        "platform_number = '7900379'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvPyKDztGWUP"
      },
      "source": [
        "### 5.2.3 Extract profiles from selected float and interpolate the profile onto custom pressure levels. Print a table with profile date, location, observed data (after interpolation) and QC flag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Obyw_e5GiOm"
      },
      "source": [
        "\n",
        "platformProfiles = get_platform_profiles(platform_number) #'3900737')#('5904684')\n",
        "# platformDf = parse_into_df(platformProfiles)\n",
        "# print('number of measurements {}'.format(platformDf.shape[0]))\n",
        "plevIntp = np.arange(5,505,5)\n",
        "platformDf_plev = parse_into_df_plev(platformProfiles, plevIntp)\n",
        "platformDf_plev.head()\n",
        "temp2d = np.concatenate(platformDf_plev['temp'].to_numpy()).ravel().reshape(len(platformDf_plev['temp']),len(plevIntp)).T\n",
        "psal2d = np.concatenate(platformDf_plev['psal'].to_numpy()).ravel().reshape(len(platformDf_plev['temp']),len(plevIntp)).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfUYl_qhHGJo"
      },
      "source": [
        "### 5.2.4 Plot float position colorcoded by the QC flag at each position.\n",
        "\n",
        "Recall that QC = 8 (float position is estimated)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3i98w8yHny1"
      },
      "source": [
        "fig, (ax) = plt.subplots(1,1, figsize=(15,10))\n",
        "plt.scatter(platformDf_plev['lon'],platformDf_plev['lat'],c=platformDf_plev['position_qc'],s=80)\n",
        "plt.colorbar()\n",
        "# change font\n",
        "for tick in ax.xaxis.get_majorticklabels():  # example for xaxis\n",
        "    tick.set_fontsize(24) \n",
        "for tick in ax.yaxis.get_majorticklabels():  # example for xaxis\n",
        "    tick.set_fontsize(24)\n",
        "ax.set_ylabel('Degree latitude',size=24,labelpad=0)\n",
        "ax.set_xlabel('Degree longitude',size=24,labelpad=0)\n",
        "plt.title('Float #'+platform_number,size=24)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIy4Jw4eHw2o"
      },
      "source": [
        "### 5.2.5 Save the fraction of sea-ice (from SOSE) at each profile position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMllWSSeH7Uy"
      },
      "source": [
        "dx = 1/6 # based on SOSE resolution\n",
        "dy = 1/6 # based on SOSE resolution\n",
        "# 2013-06-01\n",
        "# <class 'str'>\n",
        "seaice_val = []\n",
        "for (ilon,ilat,idate) in zip(platformDf_plev['lon'],platformDf_plev['lat'],platformDf_plev['date']):\n",
        "    try:\n",
        "        bfr  = get_SOSE_sea_ice(xreg=[ilon-dx,ilon+dx],yreg=[ilat-dy,ilat+dy],date=idate[0:10],printUrl=False)\n",
        "        bfr_df_SeaIce       = parse_into_df_SeaIce(bfr)\n",
        "        #         print(ilon,ilat)\n",
        "        #         print(bfr_df_SeaIce)\n",
        "        seaice_val.append(interpolate.griddata((bfr_df_SeaIce['lon'],bfr_df_SeaIce['lat']),bfr_df_SeaIce['value'],(ilon,ilat)))\n",
        "        #break\n",
        "        #df = pd.concat([df, bfrDf], sort=False)\n",
        "        #find point closest to target (will not try and interpolate)\n",
        "    except:\n",
        "        seaice_val.append(np.array(0))\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8RgN9ubIRBF"
      },
      "source": [
        "### 5.2.6 Generate a multi-panel figure showing: a) time series of the float's QC flag value and fraction of sea-ice from SOSE, b) ocean temperature profiles in time as recorded by the float and, c) ocean salinity profiles in time as recorded by the float."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXKNzO6eOCYe"
      },
      "source": [
        "tdelta = 15 #maximum days permitted between profiles to avoid interpolation of profiles too far apart in time\n",
        "\n",
        "temp2d_new = np.empty((len(plevIntp),1))\n",
        "psal2d_new = np.empty((len(plevIntp),1))\n",
        "temp2d_new[:,0] = temp2d[:,0]\n",
        "psal2d_new[:,0] = psal2d[:,0]\n",
        "\n",
        "time_new = pd.Series(pd.to_datetime(platformDf_plev['date'][0]))\n",
        "for i in np.arange(1,len(platformDf_plev['date'])):\n",
        "        nnans_days = (pd.to_datetime(platformDf_plev['date'][i])-pd.to_datetime(platformDf_plev['date'][i-1])).days\n",
        "        # in the following we add 1 profile of nan in between profiles that are too far apart in time \n",
        "        # (if more profiles of nan are needed, then you need to edit np.empty and the number of iterations in j-loop)\n",
        "        if nnans_days>tdelta:\n",
        "\n",
        "            temp2d_new = np.append(temp2d_new,np.nan*np.empty((len(plevIntp),1)),axis=1)\n",
        "            psal2d_new = np.append(psal2d_new,np.nan*np.empty((len(plevIntp),1)),axis=1)\n",
        "            \n",
        "            bfr_date = pd.to_datetime(platformDf_plev['date'][i-1])\n",
        "            # this loop is now only looping once as we only need to add one profile of nans \n",
        "            for j in np.arange(1,2,1):\n",
        "                bfr_date += timedelta(days=1)\n",
        "                time_new = time_new.append(pd.Series(bfr_date))\n",
        "\n",
        "        temp2d_new = np.append(temp2d_new,temp2d[:,np.newaxis,i],axis=1)\n",
        "        psal2d_new = np.append(psal2d_new,psal2d[:,np.newaxis,i],axis=1)\n",
        "        time_new = time_new.append(pd.Series(pd.to_datetime(platformDf_plev['date'][i])))\n",
        "        \n",
        "plt.figure(figsize=(30, 20))\n",
        "for i in [1,2,3]:\n",
        "    if i==1:\n",
        "        ax = plt.subplot(311)\n",
        "        plt.plot(pd.to_datetime(platformDf_plev['date']),np.ones(np.shape(pd.to_datetime(platformDf_plev['date']))),\n",
        "                 '--b')\n",
        "        plt.plot(pd.to_datetime(platformDf_plev['date']),platformDf_plev['position_qc'],'sr',markersize=14)\n",
        "        plt.plot(pd.to_datetime(platformDf_plev['date']),np.stack( seaice_val ),'ob',markersize=12)\n",
        "        ax.set_ylabel('Position QC flag',size=24,labelpad=0)\n",
        "        plt.title('Float #'+platform_number,size=24)\n",
        "        \n",
        "    if i==2:\n",
        "        ax = plt.subplot(312)\n",
        "        mt = np.ma.masked_where(np.isnan(temp2d_new),temp2d_new)\n",
        "        plt.pcolor(pd.to_datetime(time_new),plevIntp,mt)\n",
        "        #plt.pcolormesh(pd.to_datetime(platformDf_plev['date']),plevIntp,temp2d) # pd.Series(np.arange(0,79,1))\n",
        "        plt.title('Temperature, degC',size=24)\n",
        "        \n",
        "    if i==3:\n",
        "        ax = plt.subplot(313)\n",
        "        ms = np.ma.masked_where(np.isnan(psal2d_new),psal2d_new)\n",
        "        plt.pcolor(pd.to_datetime(time_new),plevIntp,ms)\n",
        "        \n",
        "        # plt.pcolor(pd.to_datetime(platformDf_plev['date']),plevIntp,psal2d) # pd.Series(np.arange(0,79,1))\n",
        "        plt.title('Salinity, psu',size=24)\n",
        "        \n",
        "    if i==2 or i==3:\n",
        "        plt.gca().invert_yaxis()\n",
        "        ax.set_ylabel('Pressure, dbar',size=24,labelpad=0)\n",
        "        cbar = plt.colorbar(orientation=\"horizontal\", pad=0.2)\n",
        "        cbar.ax.tick_params(labelsize=24)\n",
        "        \n",
        "    # change font\n",
        "    for tick in ax.xaxis.get_majorticklabels():  # example for xaxis\n",
        "        tick.set_fontsize(24) \n",
        "    for tick in ax.yaxis.get_majorticklabels():  # example for xaxis\n",
        "        tick.set_fontsize(24)\n",
        "    plt.xlim([min(pd.to_datetime(platformDf_plev['date'])),max(pd.to_datetime(platformDf_plev['date']))])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYfkz-32Psiy"
      },
      "source": [
        "## 5.3 Activity Results\n",
        "---\n",
        "Present your results. You should leverage the information and references provided through the notebook (Sections 1.5 and 5). Make direct reference to the figures you generated throughout the activity. Use your answers to the different questions throughout the activity to guide your results narrative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yUVfcDZRXxo"
      },
      "source": [
        "insert results text here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtHW8R7CRCuw"
      },
      "source": [
        "# 6. References\n",
        "List relevant references.\n",
        "\n",
        "1. Argo (2000). Argo float data and metadata from Global Data Assembly Centre (Argo GDAC). SEANOE. https://doi.org/10.17882/42182\n",
        "2. A. Verdy and M. Mazloff, 2017: A data assimilating model for estimating Southern Ocean biogeochemistry. J. Geophys. Res. Oceans., 122, [doi:10.1002/2016JC012650.](http://sose.ucsd.edu/PAPERS/Verdy_et_al-2017-JGR.pdf)\n",
        "3. [Joint Typhoon Warning Center (JTWC).(n.d.).](https://www.metoc.navy.mil/jtwc/jtwc.html?best-tracks) \n",
        "4. M. Mazloff, P. Heimbach, and C. Wunsch, 2010: An Eddy-Permitting Southern Ocean State Estimate. J. Phys. Oceanogr., 40, 880-899. [doi:10.1175/2009JPO4236.1](http://sose.ucsd.edu/PAPERS/Mazloff_et_al-2010-JPO.pdf).\n",
        "5. [NHC Data Archive. (n.d.).](https://www.nhc.noaa.gov/data/)\n",
        "6. Priestley, M. D. K., Ackerley, D., Catto, J. L., Hodges, K. I., McDonald, R. E., & Lee, R. W. (2020). An Overview of the Extratropical Storm Tracks in CMIP6 Historical Simulations, Journal of Climate, 33(15), 6315-6343. [doi:10.1175/JCLI-D-19-0928.1.](https://journals.ametsoc.org/view/journals/clim/33/15/JCLI-D-19-0928.1.xml?tab_body=pdf)\n",
        "7. Tucker, T., Giglio, D., and Scanderbeg, M. (2020). Argovis API exposed in a Python Jupyter notebook: an easy access to Argo profiles, weather events, and gridded products. Earth and Space Science Open Archive, [doi:10.1002/essoar.10504304.1.](https://doi.org/10.1002/essoar.10504304.1)\n",
        "8. Tucker, T., Giglio, D., Scanderbeg, M., & Shen, S. S. P. (2020). Argovis: A Web Application for Fast Delivery, Visualization, and Analysis of Argo Data, Journal of Atmospheric and Oceanic Technology, 37(3), 401-416. [doi:10.1175/JTECH-D-19-0041.1.](https://journals.ametsoc.org/view/journals/atot/37/3/JTECH-D-19-0041.1.xml)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxJi0tYlRCuw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}